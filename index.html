<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>集智书童</title><meta name="keywords" content="AI算法爱好者"><meta name="author" content="ChaucerG"><meta name="copyright" content="ChaucerG"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="AI算法爱好者33">
<meta property="og:type" content="website">
<meta property="og:title" content="集智书童">
<meta property="og:url" content="https://chaucerg.github.io/index.html">
<meta property="og:site_name" content="集智书童">
<meta property="og:description" content="AI算法爱好者33">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://chaucerg.github.io/img/avatar.jpg">
<meta property="article:author" content="ChaucerG">
<meta property="article:tag" content="AI算法爱好者">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chaucerg.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://chaucerg.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: ChaucerG","link":"链接: ","source":"来源: 集智书童","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '集智书童',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-09-05 23:53:59'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-map-signs"></i><span> 目录</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fas fa-coffee"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/home_img.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">集智书童</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-map-signs"></i><span> 目录</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fas fa-coffee"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">集智书童</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/ChaucerG" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chaucer_g@126.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/img/weixin.jpg" target="_blank" title="Wechat"><i class="fab fa-weixin"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/09/05/%E5%8D%B7%E7%A7%AF%E4%B8%8ESelf-Attention%E5%AE%8C%E7%BE%8E%E8%9E%8D%E5%90%88X-volution%E6%8F%92%E5%85%A5CV%E6%A8%A1%E5%9E%8B%E5%B0%86%E5%B8%A6%E6%9D%A5%E5%85%A8%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B6%A8%E7%82%B9/" title="卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E5%8D%B7%E7%A7%AF%E4%B8%8ESelf-Attention%E5%AE%8C%E7%BE%8E%E8%9E%8D%E5%90%88X-volution%E6%8F%92%E5%85%A5CV%E6%A8%A1%E5%9E%8B%E5%B0%86%E5%B8%A6%E6%9D%A5%E5%85%A8%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B6%A8%E7%82%B9/" title="卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点">卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T15:35:11.000Z" title="发表于 2021-09-05 23:35:11">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T15:53:13.026Z" title="更新于 2021-09-05 23:53:13">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%8D%B7%E7%A7%AFCNN/">卷积CNN</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8D%B7%E7%A7%AF/">卷积</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Self-Attention/">Self-Attention</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CV%E6%A8%A1%E5%9E%8B/">CV模型</a></span></div><div class="content">


本文建立了一个由卷积和self-attention组成的多分支基本模块，能够统一局部和非局部特征交互，然后可以结构重新参数化为一个纯卷积风格的算子：X-volution，即插即用！可助力分类、检测和分割任务的涨点！作者单位：上海交通大学(倪冰冰团队), 华为海思

简介卷积和self-attention是深度神经网络中的2个基本构建块，前者以线性方式提取图像的局部特征，而后者通过非局部关系编码高阶上下文关系。尽管本质上是相互补充的，即一阶/高阶、最先进的架构，但是，CNN或Transformer均缺乏一种原则性的方法来在单个计算模块中同时应用这2种操作，因为它们的异构计算视觉任务的全局点积的模式和过度负担。
在这项工作中，作者从理论上推导出一种全局self-attention近似方案，该方案通过对变换特征的卷积运算来近似self-attention。基于近似方案建立了一个由卷积和self-attention操作组成的多分支基本模块，能够统一局部和非局部特征交互。重要的是，一旦经过训练，这个多分支模块可以通过结构重新参数化有条件地转换为单个标准卷积操作，呈现一个名为X-voluti ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/09/05/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBTransformer%E6%80%8E%E6%A0%B7%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%B6%85%E8%B6%8AResNet/" title="详细解读Transformer怎样从零训练并超越ResNet">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详细解读Transformer怎样从零训练并超越ResNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBTransformer%E6%80%8E%E6%A0%B7%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%B6%85%E8%B6%8AResNet/" title="详细解读Transformer怎样从零训练并超越ResNet">详细解读Transformer怎样从零训练并超越ResNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T14:59:08.000Z" title="发表于 2021-09-05 22:59:08">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T15:34:12.786Z" title="更新于 2021-09-05 23:34:12">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Transformer/">Transformer</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ResNet/">ResNet</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Tricks/">Tricks</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">图像分类</a></span></div><div class="content">


本文证明了在没有大规模预训练或强数据增广的情况下，在ImageNet上从头开始训练时，所得ViT的性能优于类似大小和吞吐量的ResNet！而且还拥有更敏锐的注意力图。作者单位：谷歌,UCLA

简介Vision Transformers(ViTs)和MLPs标志着在用通用神经架构替换手动特征或归纳偏置方面的进一步努力。现有工作通过大量数据为模型赋能，例如大规模预训练和/或重复的强数据增广，并且还报告了与优化相关的问题（例如，对初始化和学习率的敏感性）。
因此，本文从损失几何的角度研究了ViTs和MLP-Mixer，旨在提高模型在训练和推理时的泛化效率。可视化和Hessian揭示了收敛模型极其敏感的局部最小值。
同时通过使用最近提出的锐度感知优化器提高平滑度，进而大大提高了ViT和MLP-Mixer在跨越监督、对抗、对比和迁移学习（例如，+5.3\% 和 +11.0\%）的各种任务上的准确性和鲁棒性使用简单的Inception进行预处理，ViT-B/16和Mixer-B/16在ImageNet上的准确率分别为Top-1）。
作者研究表明，改进的平滑度归因于前几层中较稀疏的活动神经元 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/09/05/%E5%A4%9A%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94MSDA-YOLO%E8%A7%A3%E8%AF%BB%EF%BC%8C%E6%81%B6%E5%8A%A3%E5%A4%A9%E6%B0%94%E4%B9%9F%E7%9C%8B%E5%BE%97%E8%A7%81/" title="多域自适应MSDA-YOLO解读，恶劣天气也看得见">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多域自适应MSDA-YOLO解读，恶劣天气也看得见"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E5%A4%9A%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94MSDA-YOLO%E8%A7%A3%E8%AF%BB%EF%BC%8C%E6%81%B6%E5%8A%A3%E5%A4%A9%E6%B0%94%E4%B9%9F%E7%9C%8B%E5%BE%97%E8%A7%81/" title="多域自适应MSDA-YOLO解读，恶劣天气也看得见">多域自适应MSDA-YOLO解读，恶劣天气也看得见</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T14:54:13.000Z" title="发表于 2021-09-05 22:54:13">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T15:24:13.526Z" title="更新于 2021-09-05 23:24:13">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/YOLO/">YOLO</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/YOLO/">YOLO</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></span></div><div class="content">


本文介绍了一种新的多尺度域自适应YOLO(MS-DAYOLO)框架，该框架在YOLOv4检测器的不同尺度上使用多个域自适应路径和相应的域分类器来生成域不变特征。

简介Domain Adaptation在解决许多应用中遇到的Domain Shift问题方面发挥了重要作用。这个问题的出现是由于用于训练的源数据的分布与实际测试场景中使用的目标数据之间存在差异。

 本文介绍了一种新的多尺度域自适应YOLO(MS-DAYOLO)框架，该框架在YOLOv4检测器的不同尺度上使用多个域自适应路径和相应的域分类器来生成域不变特征。实验表明，当使用本文提出的MS-DAYOLO训练YOLOv4时，以及在自动驾驶应用中具有挑战性的天气条件的目标数据上进行测试时，目标检测性能得到了显著改善。
方法2.1 YOLO V4简述相对于YOLO V3，YOLOv4包含了许多新的改进和新技术，以提高整体检测精度。

如图所示YOLOv4有3个主要部分:backbone、neck和head。
backbone负责提取不同尺度下的多层特征。
neck使用上采样层将backbone的3种不同尺度的特征聚集在一起，并 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/09/05/%E6%B2%A1%E6%9C%89Attention%E7%9A%84Transformer%E4%BE%9D%E7%84%B6%E6%98%AF%E9%A1%B6%E6%B5%81%EF%BC%81%EF%BC%81%EF%BC%81/" title="没有Attention的Transformer依然是顶流！！！">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="没有Attention的Transformer依然是顶流！！！"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E6%B2%A1%E6%9C%89Attention%E7%9A%84Transformer%E4%BE%9D%E7%84%B6%E6%98%AF%E9%A1%B6%E6%B5%81%EF%BC%81%EF%BC%81%EF%BC%81/" title="没有Attention的Transformer依然是顶流！！！">没有Attention的Transformer依然是顶流！！！</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T14:42:39.000Z" title="发表于 2021-09-05 22:42:39">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T15:31:11.213Z" title="更新于 2021-09-05 23:31:11">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Transformer/">Transformer</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Tansformer/">Tansformer</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Attention/">Attention</a></span></div><div class="content">


本文主要介绍了Attention Free Transformer(AFT)，同时作者还引入了AFT-local和AFT-Conv，这两个模型在保持全局连通性的同时，利用了局域性和空间权重共享的思想。通过实验验证了AFT在所有benchmarks上具有竞争性能的同时具有出色的效率。

简介本文主要介绍了Attention Free Transformer(AFT)，在AFT层中，首先将key和value与一组学习到的位置偏差结合起来，然后以元素方式将其结果与query相乘。这个新的操作在context size和特征维度上都具有线性的内存复杂度，使得它能够兼容大的输入和模型大小。
作者还引入了AFT-local和AFT-Conv，这两个模型变种在保持全局连通性的同时还利用了局域性和空间权重共享的思想。作者对2个自回归建模任务(CIFAR10和Enwik8)以及一个图像识别任务(ImageNet-1K分类)进行了广泛的实验。验证了AFT在所有benchmarks上不仅具有不错的性能，同时还具有出色的效率。
本文方法2.1 Attention Free Transformer首先，定 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/09/05/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E5%8C%96%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E2%80%94%E2%80%94EAIDK310%E9%83%A8%E7%BD%B2%E7%AF%87/" title="从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E5%8C%96%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E2%80%94%E2%80%94EAIDK310%E9%83%A8%E7%BD%B2%E7%AF%87/" title="从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇">从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T14:29:27.000Z" title="发表于 2021-09-05 22:29:27">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T14:43:47.127Z" title="更新于 2021-09-05 22:43:47">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/">项目部署</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/">人脸识别</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/">人脸检测</a></span></div><div class="content">



继续上一章的话题，前面我们主要聊到关于人脸检测模型UltraFace的训练任务，本文将和大家讨论在开发板上如何部署UltraFace模型，并进行实时视频人脸检测，或者图片流人脸检测。

Tengine简介Tengine 由 OPEN AI LAB 主导开发，该项目实现了深度学习神经网络模型在嵌入式设备上的快速、高效部署需求。为实现在众多 AIoT 应用中的跨平台部署，本项目基于原有 Tengine 项目使用 C 语言进行重构，针对嵌入式设备资源有限的特点进行了深度框架裁剪。同时采用了完全分离的前后端设计，有利于 CPU、GPU、NPU 等异构计算单元的快速移植和部署，同时降低评估和迁移成本。
Tengine推理流程依照顺序调用Tengine核心API如下：

模块实现1 模型转换第1步：转换到onnx模型1234567891011model_path = &quot;models/pretrained/version-RFB-320.pth&quot;net = create_Mb_Tiny_RFB_fd(len(class_names), is_test=True)net.l ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/09/05/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E5%8C%96%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83%E7%AF%87/" title="从零开始边缘部署轻量化人脸检测模型————训练篇">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从零开始边缘部署轻量化人脸检测模型————训练篇"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E5%8C%96%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83%E7%AF%87/" title="从零开始边缘部署轻量化人脸检测模型————训练篇">从零开始边缘部署轻量化人脸检测模型————训练篇</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T14:03:12.000Z" title="发表于 2021-09-05 22:03:12">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T15:32:39.504Z" title="更新于 2021-09-05 23:32:39">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/">项目实践</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/">人脸识别</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/">人脸检测</a></span></div><div class="content">

简介该模型是针对边缘计算设备设计的轻量人脸检测模型。

在模型大小上，默认FP32精度下（.pth）文件大小为 1.04~1.1MB，推理框架int8量化后大小为 300KB 左右。
在模型计算量上，320x240的输入分辨率下 90~109 MFlops左右。
模型有两个版本，version-slim(主干精简速度略快)，version-RFB(加入了修改后的RFB模块，精度更高)。
提供320x240、640x480不同输入分辨率下使用widerface训练的预训练模型，更好的工作于不同的应用场景。

数据处理2.1 输入尺寸的选择由于涉及实际部署时的推理速度，因此模型输入尺寸的选择也是一个很重要的话题。
在作者的原github中，也提到了一点，如果在实际部署的场景中大多数情况为中近距离、人脸大同时人脸的数量也比较少的时候，则可以采用$320\times 240$的输入尺寸；
如果在实际部署的场景中大多数情况为中远距离、人脸小同时人脸的数量也比较多的时候，则可以采用$640\times 480$或者$480\times 360$的输入尺寸；

这里由于使用的是EAIDK310进 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/09/05/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBTransformer%E9%82%A3%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E7%89%B9%E6%80%A7/" title="详细解读Transformer那些有趣的特性">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详细解读Transformer那些有趣的特性"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBTransformer%E9%82%A3%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E7%89%B9%E6%80%A7/" title="详细解读Transformer那些有趣的特性">详细解读Transformer那些有趣的特性</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T11:35:45.000Z" title="发表于 2021-09-05 19:35:45">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T14:43:57.028Z" title="更新于 2021-09-05 22:43:57">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Transformer/">Transformer</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">

本文发现了Transformer的一些重要特性，如Transformer对严重的遮挡，扰动和域偏移具有很高的鲁棒性、与CNN相比，ViT更符合人类视觉系统，泛化性更强，等等…  代码即将开源！作者单位：澳大利亚国立大学, 蒙纳士大学, 谷歌等7家高校/企业
简介
近期Vision Transformer（ViT）在各个垂直任务上均表现出非常不错的性能。这些模型基于multi-head自注意力机制，该机制可以灵活地处理一系列图像patches以对上下文cues进行编码。


一个重要的问题是，在以给定patch为条件的图像范围内，如何灵活地处理图像中的干扰，例如严重的遮挡问题、域偏移问题、空间排列问题、对抗性和自然扰动等等问题。作者通过涵盖3个ViT系列的大量实验，以及与高性能卷积神经网络（CNN）的比较，系统地研究了这些问题。并通过分析得出了ViT的以下的特性：
1) Transformer对严重的遮挡，扰动和域偏移具有很高的鲁棒性，例如，即使随机遮挡80％的图像内容，其在ImageNet上仍可保持高达60％的top-1精度; 
2) Transformer对于遮挡的良好表现并不是 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/09/05/%E5%9C%A8ResNet%E4%B8%8ETransformer%E5%9D%87%E9%80%82%E7%94%A8%E7%9A%84Skip%20Connection%E8%A7%A3%E8%AF%BB/" title="在ResNet与Transformer均适用的Skip Connection解读">     <img class="post_bg" src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="在ResNet与Transformer均适用的Skip Connection解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/09/05/%E5%9C%A8ResNet%E4%B8%8ETransformer%E5%9D%87%E9%80%82%E7%94%A8%E7%9A%84Skip%20Connection%E8%A7%A3%E8%AF%BB/" title="在ResNet与Transformer均适用的Skip Connection解读">在ResNet与Transformer均适用的Skip Connection解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-05T09:16:48.000Z" title="发表于 2021-09-05 17:16:48">2021-09-05</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-05T14:44:02.499Z" title="更新于 2021-09-05 22:44:02">2021-09-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%8D%B7%E7%A7%AFCNN/">卷积CNN</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/">残差连接</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CNN/">CNN</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Tansformer/">Tansformer</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/ResNet/">ResNet</a></span></div><div class="content">

该文主要是分析和讨论了跳跃连接的一些局限，同时分析了BN的一些限制，提出了通过递归的Skip connection和layer normalization来自适应地调整输入scale的策略，可以很好的提升跳Skip connection的性能，该方法在CV和NLP领域均适用。

简介Skip connection是一种广泛应用于提高深度神经网络性能和收敛性的技术，它通过神经网络层传播的线性分量，缓解了非线性带来的优化困难。但是，从另一个角度来看，它也可以看作是输入和输出之间的调制机制，输入按预定义值1进行缩放。
在本文中，作者通过研究Skip connection的有效性和scale factors显示，一个微不足道的调整将导致spurious gradient爆炸或消失，这可以通过normalization来解决，特别是layer normalization。受此启发作者进一步提出通过递归的Skip connection和layer normalization来自适应地调整输入scale，这大大提高了性能，并且在包括机器翻译和图像分类数据集在内的各种任务中具有很好的泛化效果。

 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ChaucerG</div><div class="author-info__description">干就完了！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ChaucerG"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ChaucerG" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chaucer_g@126.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/img/weixin.jpg" target="_blank" title="Wechat"><i class="fab fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">更多内容可以关注【集智书童】公众号和【集智书童】知识星球，获取原创文章以及项目源码 ~</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/09/05/%E5%8D%B7%E7%A7%AF%E4%B8%8ESelf-Attention%E5%AE%8C%E7%BE%8E%E8%9E%8D%E5%90%88X-volution%E6%8F%92%E5%85%A5CV%E6%A8%A1%E5%9E%8B%E5%B0%86%E5%B8%A6%E6%9D%A5%E5%85%A8%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B6%A8%E7%82%B9/" title="卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点"><img src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点"/></a><div class="content"><a class="title" href="/2021/09/05/%E5%8D%B7%E7%A7%AF%E4%B8%8ESelf-Attention%E5%AE%8C%E7%BE%8E%E8%9E%8D%E5%90%88X-volution%E6%8F%92%E5%85%A5CV%E6%A8%A1%E5%9E%8B%E5%B0%86%E5%B8%A6%E6%9D%A5%E5%85%A8%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B6%A8%E7%82%B9/" title="卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点">卷积与Self-Attention完美融合X-volution插入CV模型将带来全任务的涨点</a><time datetime="2021-09-05T15:35:11.000Z" title="发表于 2021-09-05 23:35:11">2021-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/05/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBTransformer%E6%80%8E%E6%A0%B7%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%B6%85%E8%B6%8AResNet/" title="详细解读Transformer怎样从零训练并超越ResNet"><img src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详细解读Transformer怎样从零训练并超越ResNet"/></a><div class="content"><a class="title" href="/2021/09/05/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBTransformer%E6%80%8E%E6%A0%B7%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%B6%85%E8%B6%8AResNet/" title="详细解读Transformer怎样从零训练并超越ResNet">详细解读Transformer怎样从零训练并超越ResNet</a><time datetime="2021-09-05T14:59:08.000Z" title="发表于 2021-09-05 22:59:08">2021-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/05/%E5%A4%9A%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94MSDA-YOLO%E8%A7%A3%E8%AF%BB%EF%BC%8C%E6%81%B6%E5%8A%A3%E5%A4%A9%E6%B0%94%E4%B9%9F%E7%9C%8B%E5%BE%97%E8%A7%81/" title="多域自适应MSDA-YOLO解读，恶劣天气也看得见"><img src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多域自适应MSDA-YOLO解读，恶劣天气也看得见"/></a><div class="content"><a class="title" href="/2021/09/05/%E5%A4%9A%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94MSDA-YOLO%E8%A7%A3%E8%AF%BB%EF%BC%8C%E6%81%B6%E5%8A%A3%E5%A4%A9%E6%B0%94%E4%B9%9F%E7%9C%8B%E5%BE%97%E8%A7%81/" title="多域自适应MSDA-YOLO解读，恶劣天气也看得见">多域自适应MSDA-YOLO解读，恶劣天气也看得见</a><time datetime="2021-09-05T14:54:13.000Z" title="发表于 2021-09-05 22:54:13">2021-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/05/%E6%B2%A1%E6%9C%89Attention%E7%9A%84Transformer%E4%BE%9D%E7%84%B6%E6%98%AF%E9%A1%B6%E6%B5%81%EF%BC%81%EF%BC%81%EF%BC%81/" title="没有Attention的Transformer依然是顶流！！！"><img src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="没有Attention的Transformer依然是顶流！！！"/></a><div class="content"><a class="title" href="/2021/09/05/%E6%B2%A1%E6%9C%89Attention%E7%9A%84Transformer%E4%BE%9D%E7%84%B6%E6%98%AF%E9%A1%B6%E6%B5%81%EF%BC%81%EF%BC%81%EF%BC%81/" title="没有Attention的Transformer依然是顶流！！！">没有Attention的Transformer依然是顶流！！！</a><time datetime="2021-09-05T14:42:39.000Z" title="发表于 2021-09-05 22:42:39">2021-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/05/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E5%8C%96%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E2%80%94%E2%80%94EAIDK310%E9%83%A8%E7%BD%B2%E7%AF%87/" title="从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇"><img src="/img/achieve_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇"/></a><div class="content"><a class="title" href="/2021/09/05/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%BE%B9%E7%BC%98%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E5%8C%96%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E2%80%94%E2%80%94EAIDK310%E9%83%A8%E7%BD%B2%E7%AF%87/" title="从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇">从零开始边缘部署轻量化人脸检测模型————EAIDK310部署篇</a><time datetime="2021-09-05T14:29:27.000Z" title="发表于 2021-09-05 22:29:27">2021-09-05</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Transformer/"><span class="card-category-list-name">Transformer</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/YOLO/"><span class="card-category-list-name">YOLO</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%8D%B7%E7%A7%AFCNN/"><span class="card-category-list-name">卷积CNN</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"><span class="card-category-list-name">项目实践</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/"><span class="card-category-list-name">项目部署</span><span class="card-category-list-count">1</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 1.45em; color: rgb(53, 76, 11)">人脸识别</a><a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 1.45em; color: rgb(10, 56, 120)">人脸检测</a><a href="/tags/%E5%8D%B7%E7%A7%AF/" style="font-size: 1.15em; color: rgb(40, 82, 161)">卷积</a><a href="/tags/Self-Attention/" style="font-size: 1.15em; color: rgb(0, 188, 154)">Self-Attention</a><a href="/tags/CV%E6%A8%A1%E5%9E%8B/" style="font-size: 1.15em; color: rgb(151, 97, 114)">CV模型</a><a href="/tags/YOLO/" style="font-size: 1.15em; color: rgb(24, 130, 197)">YOLO</a><a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.15em; color: rgb(78, 109, 28)">目标检测</a><a href="/tags/%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/" style="font-size: 1.15em; color: rgb(168, 193, 94)">残差连接</a><a href="/tags/CNN/" style="font-size: 1.15em; color: rgb(40, 23, 143)">CNN</a><a href="/tags/Tansformer/" style="font-size: 1.45em; color: rgb(85, 5, 24)">Tansformer</a><a href="/tags/ResNet/" style="font-size: 1.45em; color: rgb(189, 92, 23)">ResNet</a><a href="/tags/Attention/" style="font-size: 1.15em; color: rgb(57, 40, 139)">Attention</a><a href="/tags/Transformer/" style="font-size: 1.45em; color: rgb(165, 175, 158)">Transformer</a><a href="/tags/Tricks/" style="font-size: 1.15em; color: rgb(191, 27, 38)">Tricks</a><a href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" style="font-size: 1.15em; color: rgb(153, 40, 71)">图像分类</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">8</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">8</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2021-01-07T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-09-05T15:53:58.907Z"></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/home_img.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2021 By ChaucerG</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to my CHANNEL!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "抱有一颗终身学习的心&#44; 持续前进 ~,Study till the end of my life ~".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '抱有一颗终身学习的心&#44; 持续前进 ~'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>